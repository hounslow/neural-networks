{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 340 a5 q3: recommender systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we'll be exploring movie recommendations using the [MovieLens](https://grouplens.org/datasets/movielens/) dataset. We'll use the small version of the data set which you can \n",
    "[here](http://files.grouplens.org/datasets/movielens/ml-latest-small.zip). **Before proceeding, please download it and put the unzipped `ml-latest-small` directory inside your `data` directory.** The structure of the data is described in the [README](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html) that comes with the data. \n",
    "\n",
    "Dependencies: you'll need the Pandas package for this question. If you're using Anaconda, you'll already have it. Otherwise you should be able to get it with `pip install pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.linalg as npla\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing the ratings data\n",
    "\n",
    "Let's start by looking at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1293</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1339</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1260759125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1343</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205\n",
       "5       1     1263     2.0  1260759151\n",
       "6       1     1287     2.0  1260759187\n",
       "7       1     1293     2.0  1260759148\n",
       "8       1     1339     3.5  1260759125\n",
       "9       1     1343     2.0  1260759131"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(os.path.join(\"..\", \"data\", \"ml-latest-small\", \"ratings.csv\"))\n",
    "ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the `ratings` DataFrame contains one row per rating, which tells us the `userId` of the person giving the rating, the `movieId` of the movie being rating, and the rating itself out of 5 stars.\n",
    "\n",
    "The next block of code does some preprocessing and prints out some key numbers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users (N)                : 671\n",
      "Number of movies (M)               : 9066\n",
      "Number of ratings (|R|)            : 100004\n",
      "Fraction of nonzero elements in Y  : 1.6%\n",
      "Average number of ratings per user : 149\n",
      "Average number of ratings per movie: 11\n"
     ]
    }
   ],
   "source": [
    "N = len(np.unique(ratings[\"userId\"]))\n",
    "M = len(np.unique(ratings[\"movieId\"]))\n",
    "\n",
    "# since the id values aren't contiguous, we need a mapping from id to index of an array\n",
    "N_mapper = dict(zip(np.unique(ratings[\"userId\"]), list(range(N))))\n",
    "M_mapper = dict(zip(np.unique(ratings[\"movieId\"]), list(range(M))))\n",
    "\n",
    "print(\"Number of users (N)                : %d\" % N)\n",
    "print(\"Number of movies (M)               : %d\" % M)\n",
    "print(\"Number of ratings (|R|)            : %d\" % len(ratings))\n",
    "print(\"Fraction of nonzero elements in Y  : %.1f%%\" % (len(ratings)/(N*M)*100))\n",
    "print(\"Average number of ratings per user : %.0f\" % (len(ratings)/N))\n",
    "print(\"Average number of ratings per movie: %.0f\" % (len(ratings)/M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's split `ratings` into a training and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratings, valid_ratings = train_test_split(ratings, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now construct $Y$, which is defined above, from the `ratings` DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_Y_from_ratings(ratings_df, N, M):    \n",
    "    Y = np.zeros((N,M)) \n",
    "    Y.fill(np.nan)\n",
    "    for index, val in ratings_df.iterrows():\n",
    "        n = N_mapper[val[\"userId\"]]\n",
    "        m = M_mapper[val[\"movieId\"]]\n",
    "        Y[n,m] = val[\"rating\"]\n",
    "    \n",
    "    return Y\n",
    "\n",
    "Y          = create_Y_from_ratings(train_ratings, N, M)\n",
    "Y_validate = create_Y_from_ratings(valid_ratings, N, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we committed a mortal sin, which is storing `Y` as a dense numpy array. If we had more data, we would need to use a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html) data type, which we've perhaps mentioned very briefly. But for now we won't worry about it. \n",
    "\n",
    "Also, for convenience, we store the missing entries as `NaN` instead of zero. The reason will become apparent soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs we are storing in `Y` because Mike is sloppy: 6.0e+06\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of NaNs we are storing in `Y` because Mike is sloppy: %.1e\" % (N*M-len(ratings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducting the notation\n",
    "\n",
    "Here is some notation we will be using. This is different from what we have been doing in class (sorry).\n",
    "\n",
    "**Constants**:\n",
    "\n",
    " - $N$: the number of users, indexed by $n$.\n",
    " - $M$: the number of movies, indexed by $m$.\n",
    " - $d$: the nubmer of movie features (more on this later).\n",
    " - $k$: the number of latent dimensions we use (more on this later).\n",
    " - $\\mathcal{R}$: the set of indices $(n,m)$ where we have ratings in $Y$ (so $|\\mathcal{R}|$ is the total number of ratings).\n",
    " \n",
    "**The data**:\n",
    "\n",
    " - $Y$: the matrix containing the ratings (size $N\\times M$), with a lot of missing entries. $y_{nm}$ is one rating.\n",
    " - $Z$: a matrix whose rows $z_m$ represent the features for movie $m$ (size $M\\times d$).\n",
    " \n",
    "**Learned parameters** (more on these later):\n",
    "\n",
    " - $b_n$: a bias variable specific to user $n$.\n",
    " - $b_m$: a bias variable specific to movie $m$.\n",
    " - $U$: a matrix whose rows $u_n^T$ represent latent features for user $n$ (size $N \\times k$).\n",
    " - $V$ : a matrix whose columns $v_m$ represent latent features for movie $m$ (size $k \\times M$).  \n",
    " - $w$: the weight vector for linear regression on the movie features (length $d$).\n",
    " - $w_n$: the same as $w$ but separate for each user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing the features\n",
    "\n",
    "Later on we'll try to use some features or \"context\" to help us make recommendations. We'll just use the genres of the movies although these aren't particularly great features. We'll store the features in a matrix called $Z$, which has size $M\\times d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>[Adventure, Children, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                              genres  \n",
       "0  [Adventure, Animation, Children, Comedy, Fantasy]  \n",
       "1                     [Adventure, Children, Fantasy]  \n",
       "2                                  [Comedy, Romance]  \n",
       "3                           [Comedy, Drama, Romance]  \n",
       "4                                           [Comedy]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(os.path.join(\"..\", \"data\", \"ml-latest-small\", \"movies.csv\"))\n",
    "movies[\"genres\"] = movies[\"genres\"].apply(lambda x: x.split(\"|\"))\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `movies` DataFrame, loaded above, contains the movie titles and genres.\n",
    "\n",
    "We'll start by just using the genres, with binary features representing the presence/absense of a particular genre. If you want, later on you can consider using other features like the year or even title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 20 genres and thus 20 (binary) movie features.\n",
      "\n",
      "Here they are:\n",
      "\n",
      " * Sci-Fi\n",
      " * IMAX\n",
      " * War\n",
      " * (no genres listed)\n",
      " * Thriller\n",
      " * Romance\n",
      " * Crime\n",
      " * Mystery\n",
      " * Adventure\n",
      " * Musical\n",
      " * Film-Noir\n",
      " * Fantasy\n",
      " * Action\n",
      " * Documentary\n",
      " * Horror\n",
      " * Western\n",
      " * Comedy\n",
      " * Children\n",
      " * Animation\n",
      " * Drama\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genres_set = set(g for G in movies[\"genres\"] for g in G)\n",
    "d = len(genres_set) \n",
    "print(\"We have %d genres and thus %d (binary) movie features.\\n\" % (d,d))\n",
    "print(\"Here they are:\\n\\n * %s\\n\" % \"\\n * \".join(genres_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, `(no genres listed)` is left in as a feature. You could remove this and have movies with no genre have the zero vectror as their feature vector. This would make $d=19$ instead of $d=20$. I'm not sure it matters much. \n",
    "\n",
    "We now preprocess the features to get them into our `Z` matrix. Again, this should probably be a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of genres per movie: 2.2\n"
     ]
    }
   ],
   "source": [
    "# preprocess the features\n",
    "genres_dict = {g:i for i,g in enumerate(genres_set)}\n",
    "Z = np.zeros((M,d))\n",
    "for index, val in movies.iterrows():\n",
    "    if val[\"movieId\"] not in M_mapper: # movie wasn't rated (but I thought those weren't supposed to be included??)\n",
    "        continue\n",
    "    m = M_mapper[val[\"movieId\"]]\n",
    "    for g in val[\"genres\"]: \n",
    "        Z[m,genres_dict[g]] = 1\n",
    "\n",
    "print(\"Average number of genres per movie: %.1f\" % (np.sum(Z)/M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, if you check out the [MovieLens](https://grouplens.org/datasets/movielens/) page you'll see there's a bigger version of the data set that includes \"tag genome\" data, which can basically be used as more features. I wrote some code to preprocess these features but am not including it here as I think there's enough going on. If you are interested, you could try that, but it involves quite a bit of data wrangling -- you probably won't have time until after the course ends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing the models\n",
    "\n",
    "Here are the models we'll consider for our recommender system:\n",
    "\n",
    "1. global average rating\n",
    "2. user average rating\n",
    "3. movie average rating\n",
    "4. average of (2) and (3) above\n",
    "5. linear regression on movie features, globally\n",
    "6. linear regression on movie features, separately for each user\n",
    "7. SVD (naively treating missing entries as 0)\n",
    "8. SVD (treating missing entries as missing, via gradient descent)\n",
    "9. Combining (8) with (6)\n",
    "10. Same as (9) but trained using SGD instead of GD\n",
    "\n",
    "Roughly speaking, we are going to be learning models that look like\n",
    "\n",
    "$$\\hat{y}_{nm} = \\frac{b_u + b_m}{2} + u_n^T v_m + w_n^T z_m$$\n",
    "\n",
    "The model above in particular corresponds to model (9) above. Take your time to digest this before proceeding. You may need to refer back to the notation above. I know you're used to $w$ and $z$ being the latent factors and factor loadings, but I'm using $v$ and $u$ for those since I need $w$ and $z$ to serve a different purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our loss function\n",
    "\n",
    "For all approaches we will measure performance with mean squared error on the validation set, which means that our error for a particular set of predictions $\\hat{y}_{nm}$ is given by\n",
    "\n",
    "$$ f(\\textrm{parameters})= \\frac{1}{|\\mathcal{R}|} \\sum_{(n,m)\\in\\mathcal{R}} (y_{nm} − \\hat{y}_{nm})^2 $$\n",
    "\n",
    "where $y_{nm}$ is the true rating and $\\hat{y}_{nm}$ is the predicted rating.\n",
    "\n",
    "The function below will compute this score for us. The `nanmean` function takes the mean of all elements but ignores the NaN values. This is why we set up $Y$ to have the missing enties as `NaN` instead of zero -- it's just very convenient now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(Y1, Y2):\n",
    "    return np.nanmean( (Y1-Y2)**2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The experiments: methods 1-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1. Global average **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train loss: 1.118415\n",
      "Global average valid loss: 1.123799\n"
     ]
    }
   ],
   "source": [
    "avg = np.nanmean(Y)\n",
    "Y_pred_1 = np.zeros(Y.shape) + avg\n",
    "print(\"Global average train loss: %f\" % score(Y_pred_1, Y))\n",
    "print(\"Global average valid loss: %f\" % score(Y_pred_1, Y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. Per-user average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user average train loss: 0.912084\n",
      "Per-user average valid loss: 0.924141\n"
     ]
    }
   ],
   "source": [
    "avg_n = np.nanmean(Y,axis=1)\n",
    "avg_n[np.isnan(avg_n)] = avg\n",
    "Y_pred_2 = np.tile(avg_n[:,None], (1,M))\n",
    "print(\"Per-user average train loss: %f\" % score(Y_pred_2, Y))\n",
    "print(\"Per-user average valid loss: %f\" % score(Y_pred_2, Y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3. Per-movie average **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-movie average train loss: 0.790202\n",
      "Per-movie average valid loss: 0.995547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: Mean of empty slice\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "avg_m = np.nanmean(Y,axis=0)\n",
    "avg_m[np.isnan(avg_m)] = avg # if you have zero ratings for a movie, use global average\n",
    "Y_pred_3 = np.tile(avg_m[None,:], (N,1))\n",
    "print(\"Per-movie average train loss: %f\" % score(Y_pred_3, Y))\n",
    "print(\"Per-movie average valid loss: %f\" % score(Y_pred_3, Y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4. Average of per-user and per-movie averages **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user and per-movie average train loss: 0.747115\n",
      "Per-user and per-movie average valid loss: 0.852226\n"
     ]
    }
   ],
   "source": [
    "# Y_pred_4 \n",
    "Y_pred_4 = (Y_pred_3 + Y_pred_2)/2\n",
    "\n",
    "print(\"Per-user and per-movie average train loss: %f\" % score(Y_pred_4, Y))\n",
    "print(\"Per-user and per-movie average valid loss: %f\" % score(Y_pred_4, Y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5. Linear regression with movie features **\n",
    "\n",
    "Note: in this model we predict the same thing for each movie, regardless of the user, like in (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take training set ratings and put them in a vector\n",
    "def get_lr_data(ratings_df, d):\n",
    "    lr_y = np.zeros(len(ratings_df))\n",
    "    lr_X = np.zeros((len(ratings_df), d))\n",
    "    i=0\n",
    "    for index, val in ratings_df.iterrows():\n",
    "        m = M_mapper[val[\"movieId\"]]\n",
    "        lr_X[i] = Z[m]\n",
    "        lr_y[i] = val[\"rating\"]\n",
    "        i += 1\n",
    "    return lr_X, lr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_features_train, lr_targets_train = get_lr_data(train_ratings, d)\n",
    "lr_features_valid, lr_targets_valid = get_lr_data(valid_ratings, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre features train loss: 1.081643\n",
      "Genre features valid loss: 1.088417\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "# print(lr_targets_train)\n",
    "lr.fit(lr_features_train, lr_targets_train)\n",
    "Y_pred_5 = np.tile(lr.predict(Z), (N,1))\n",
    "print(\"Genre features train loss: %f\" % score(Y_pred_5, Y))\n",
    "print(\"Genre features valid loss: %f\" % score(Y_pred_5, Y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 6 Per-user linear regressions on genre **\n",
    "\n",
    "Below we do the preprocessing for you. But you'll probably need to read through the preprocessing code and understand it in order to finish the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_lr_data_per_user(ratings_df, d):\n",
    "    lr_y = defaultdict(list)\n",
    "    lr_X = defaultdict(list)\n",
    "\n",
    "    for index, val in ratings_df.iterrows():\n",
    "        n = N_mapper[val[\"userId\"]]\n",
    "        m = M_mapper[val[\"movieId\"]]\n",
    "        lr_X[n].append(Z[m])\n",
    "        lr_y[n].append(val[\"rating\"])\n",
    "\n",
    "    for n in lr_X:\n",
    "        lr_X[n] = np.array(lr_X[n])\n",
    "        lr_y[n] = np.array(lr_y[n])\n",
    "        \n",
    "    return lr_X, lr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_featres_train_usr, lr_targets_train_usr = get_lr_data_per_user(train_ratings, d)\n",
    "lr_featres_valid_usr, lr_targets_valid_usr = get_lr_data_per_user(valid_ratings, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user genre features train loss: 0.715232\n",
      "Per-user genre features valid loss: 1.040050\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "# valid_loss = 0\n",
    "# train_loss = 0\n",
    "Y_pred_6 = np.zeros((N, M))\n",
    "for keys in lr_featres_train_usr.keys():\n",
    "    lr.fit(lr_featres_train_usr.get(keys), lr_targets_train_usr.get(keys))\n",
    "    Y_pred_6[keys] = lr.predict(Z)\n",
    "\n",
    "print(\"Per-user genre features train loss: %f\" % score(Y_pred_6, Y))\n",
    "print(\"Per-user genre features valid loss: %f\" % score(Y_pred_6, Y_validate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 7. SVD with per-user and per-movie averages **\n",
    "\n",
    "(It would probably be a good idea to use [sparse SVD](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), but I'm not doing it).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_svd(U,V,b_n,b_m):\n",
    "    return U@V + 0.5*b_n[:,None] + 0.5*b_m[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD train loss: 0.580967\n",
      "SVD valid loss: 0.821824\n"
     ]
    }
   ],
   "source": [
    "k = 10 # defined above, the number of latent dimensions\n",
    "\n",
    "# prepare data\n",
    "Y_svd = Y - 0.5*avg_n[:,None] - 0.5*avg_m[None]\n",
    "Y_svd[np.isnan(Y_svd)] = 0\n",
    "\n",
    "svd = TruncatedSVD(n_components=k)\n",
    "U = svd.fit_transform(Y_svd)\n",
    "V = svd.components_\n",
    "Y_pred_7 = predict_svd(U,V,avg_n,avg_m)\n",
    "print(\"SVD train loss: %f\" % score(Y_pred_7, Y))\n",
    "print(\"SVD valid loss: %f\" % score(Y_pred_7, Y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 8. SVD with a proper handling of missing features **\n",
    "\n",
    "We use gradient descent to fit. We implement the gradient calculations a bit weirdly to take advantage of code vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter = 000, train = 0.747115, valid = 0.852226\n",
      "Iter = 100, train = 0.694864, valid = 0.799959\n",
      "Iter = 200, train = 0.683763, valid = 0.793479\n",
      "Iter = 300, train = 0.677333, valid = 0.791040\n",
      "Iter = 400, train = 0.672919, valid = 0.789955\n",
      "Iter = 500, train = 0.669376, valid = 0.789472\n",
      "\n",
      "SVD GD train loss: 0.669336\n",
      "SVD GD valid loss: 0.789469\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameters\n",
    "# - for the biases, we'll use the user/item averages\n",
    "# - for the latent factors, we'll use small random values\n",
    "b_n = avg_n.copy()\n",
    "b_m = avg_m.copy()\n",
    "V = 1e-5*np.random.randn(k,M)\n",
    "U = 1e-5*np.random.randn(N,k)\n",
    "\n",
    "# Optimization\n",
    "nIter = 501\n",
    "alpha = 0.0005\n",
    "\n",
    "for itera in range(nIter):\n",
    "\n",
    "    # Compute loss function value, for user's information\n",
    "    if itera % 100 == 0:\n",
    "        Ypred = predict_svd(U,V,b_n,b_m)\n",
    "        train_loss = score(Ypred, Y)\n",
    "        valid_loss = score(Ypred, Y_validate)\n",
    "        print('Iter = %03d, train = %f, valid = %f'%(itera,train_loss,valid_loss))\n",
    "\n",
    "    # Compute gradients\n",
    "    Yhat = predict_svd(U,V,b_n,b_m)\n",
    "    r = Yhat - Y\n",
    "    r[np.isnan(r)] = 0\n",
    "    g_b_n = 0.5*np.sum(r,axis=1)\n",
    "    g_b_m = 0.5*np.sum(r,axis=0)\n",
    "    g_V = U.T@r\n",
    "    g_U = r@V.T\n",
    "    \n",
    "    # Take a small step in the negative gradient directions\n",
    "    b_n -= alpha*g_b_n\n",
    "    b_m -= alpha*g_b_m\n",
    "    V -= alpha*g_V\n",
    "    U -= alpha*g_U\n",
    "    \n",
    "Y_pred_8 = predict_svd(U,V,b_n,b_m)\n",
    "print()\n",
    "print(\"SVD GD train loss: %f\" % score(Y_pred_8, Y))\n",
    "print(\"SVD GD valid loss: %f\" % score(Y_pred_8, Y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 9. Gradient descent plus per-user movie features **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter = 000, train = 0.747116, valid = 0.852227\n",
      "Iter = 100, train = 0.608287, valid = 0.760542\n",
      "Iter = 200, train = 0.581725, valid = 0.758356\n",
      "Iter = 300, train = 0.567172, valid = 0.760377\n",
      "Iter = 400, train = 0.557541, valid = 0.763486\n",
      "Iter = 500, train = 0.550244, valid = 0.766862\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameters\n",
    "# - for the biases, we'll use the user/item averages\n",
    "# - for the latent factors, we'll use small random values\n",
    "b_n = avg_n.copy()\n",
    "b_m = avg_m.copy()\n",
    "V = 1e-5*np.random.randn(k,M)\n",
    "U = 1e-5*np.random.randn(N,k)\n",
    "W = 1e-5*np.random.randn(d,N)\n",
    "\n",
    "# Optimization\n",
    "nIter = 501\n",
    "alpha = 0.0005\n",
    "\n",
    "for itera in range(nIter):\n",
    "    \n",
    "    # Compute loss function value, for user's information\n",
    "    if itera % 100 == 0:\n",
    "        Ypred = predict_svd(U,V,b_n,b_m) + (Z@W).T\n",
    "        train_loss = score(Ypred, Y)\n",
    "        valid_loss = score(Ypred, Y_validate)\n",
    "        print('Iter = %03d, train = %f, valid = %f'%(itera,train_loss,valid_loss))\n",
    "\n",
    "    Yhat = predict_svd(U,V,b_n,b_m) + (Z@W).T\n",
    "    r = Yhat - Y\n",
    "    r[np.isnan(r)] = 0\n",
    "    g_b_n = 0.5*np.sum(r,axis=1)\n",
    "    g_b_m = 0.5*np.sum(r,axis=0)\n",
    "    g_V = U.T@r\n",
    "    g_U = r@V.T\n",
    "    g_W = (r@Z).T\n",
    "    \n",
    "    # Take a small step in the negative gradient directions\n",
    "    b_n -= alpha*g_b_n\n",
    "    b_m -= alpha*g_b_m\n",
    "    V -= alpha*g_V\n",
    "    U -= alpha*g_U\n",
    "    W -= alpha*g_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-movie average train loss: 0.402538\n",
      "Per-movie average valid loss: 0.801950\n"
     ]
    }
   ],
   "source": [
    "Y_pred_9 = predict_svd(U,V,b_n, b_m)+(Z@W).T\n",
    "print(\"Per-movie average train loss: %f\" % score(Y_pred_9, Y))\n",
    "print(\"Per-movie average valid loss: %f\" % score(Y_pred_9, Y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Compare the different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = np.arange(1,10)\n",
    "\n",
    "train = [score(eval(\"Y_pred_%d\"%i), Y) for i in methods]\n",
    "valid = [score(eval(\"Y_pred_%d\"%i), Y_validate) for i in methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training MSE</th>\n",
       "      <td>1.12</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation MSE</th>\n",
       "      <td>1.12</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1    2    3    4    5    6    7    8    9\n",
       "training MSE   1.12 0.91 0.79 0.75 1.08 0.72 0.58 0.67 0.55\n",
       "validation MSE 1.12 0.92 1.00 0.85 1.09 1.04 0.82 0.79 0.77"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format # make things look prettier when printing\n",
    "df = pd.DataFrame.from_dict({\"training MSE\": train, \"validation MSE\" : valid})\n",
    "df.index = methods\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
